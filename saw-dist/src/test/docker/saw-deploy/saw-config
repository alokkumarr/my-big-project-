#
# SAW environment configuration for local testing
#

[saw-proxy]
localhost ansible_connection=local

[saw-web]
localhost ansible_connection=local

[saw-services]
localhost ansible_connection=local

[saw-services:vars]
#
# Spark configuration
#
# Workaround: As Docker DNS lookups do not work inside CentOS 7
# containers for now, Docker links are used as a workaround.  The
# hostname and port for Docker links is provided in environment
# variables, so insert them into the configuration here.
saw_spark_master_url=spark://saw-mapr:7077
saw_zookeeper_quorum=saw-mapr
saw_metadata_path=/main/metadata/
report_executor_path=/main/
saw_observe_metastore=hdfs:///main/

#
# Transport Service Executor configuration
#
saw_executor_memory_regular=512M
saw_executor_memory_fast=512M
saw_executor_cores_regular=2
saw_executor_cores_fast=2
saw_executor_result_wait_time=300

#
# Elasticsearch configuration
#
saw_elasticsearch_protocol=http
saw_elasticsearch_host=localhost
saw_elasticsearch_port=8200
saw_elasticsearch_username=
saw_elasticsearch_password=
saw_elasticsearch_data_store_limit=10000

#
# Path by project
# replace project key with meaningful name for customer & project
# replace project path with the accessible by customer like for mct customers only
# replace project root with appropriate mapr or hdfs root directory
# replace project preview limit by default set it to 10000
#
saw_workbench_project_key=workbench
saw_workbench_project_path=/raw
saw_workbench_project_root=maprfs:///data/bda
saw_workbench_preview_limit=100
saw_workbench_livy_uri=http://saw-mapr:8998/
saw_workbench_metadata=hdfs:///main/

[saw-security]
localhost ansible_connection=local
