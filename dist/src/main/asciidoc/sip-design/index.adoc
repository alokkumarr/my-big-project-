= SIP Design Guide
include::header.adoc[]

= Overview

This document describes the high-level design of the SIP platform,
including its architecture and modules.

== Interfaces

SIP has three main external interfaces: SIP Web, SIP Services and SIP
Security.  SIP Web provides a web application for creating and
executing analysis.  It builds on top of SIP Services, which provides
a REST API for creating and executing analyses.  SIP Security manages
authentication and privileges of users.

.External SIP interfaces and their use
plantuml::sip-design/figure-interfaces.pum[]

== Security

=== Authentication

Requests to SIP Services require to be authenticated.  Clients that
need authentication first request a token from the SIP Security
Service, which is then included with subsequent requests for
authentication.

The method used is http://www.haproxy.org/[JSON Web Tokens].  The
server side has a secret key, which is used to sign a set of
statements about the client during the initial authentication
sequence.  This token is then passed to the client, which provides it
with subsequent requests.  The server can then validate the token by
inspecting its signature and the secret key.

.Authentication using JSON Web Tokens
plantuml::sip-design/figure-authentication.pum[]

For more details see the <<SIP Gateway Service>> and <<SIP Security>>
sections.

=== Authorization

Clients are authorized by the SIP Gateway Service using the user
database managed by the SIP Security Service.  The database stores
users, their credentials and privileges.  Examples of privileges are
permissions to view folders, access SIP modules and so on.

= Services

== SIP Web

The SIP Web module provides a user interface for creating and
executing analyses.  It is implemented it AngularJS and makes calls to
the SIP Services REST API over HTTP.  It additionally calls SIP
Security to authenticate users and manage privileges.

The SIP Web user interface is organized into two modules: analyze and
observe.  Additionally it provides a user interface for managing users
and privileges in SIP Security.

== SIP Services

SIP Services are a collection of microservices exposed over HTTP REST
APIs.  They enable creating and executing analyses.  They are
implemented in Java and the Spring Framework.  As an exception, the
SIP Transport Service is implemented in Scala and the Play framework.

.Figure: SIP system overview
plantuml::sip-design/figure-system.pum[]

.Figure: SIP Services and their dependencies
plantuml::sip-design/figure-services.pum[]

SIP Services use MapR-DB for persistence, using the OJAI interface.
As an exception, the SIP Transport Service uses the MapR-DB binary
tables.  Additionally SIP Services access files on the MapR-FS.

=== SIP Gateway Service

The SIP Gateway Service acts as single entry point for all upstream
micro services.  It is a Spring Boot based microservice. It upholds
the concerns regarding security.  It acts as edge service and
authenticates every request that passes by it and makes sure that it
is valid.

.Gateway Service routes requests to upstream services
plantuml::sip-design/figure-gateway.pum[]

It comes with the following benefits:

. Insulates the clients from how the application is partitioned into
  micro-services

. Insulates the clients from the problem of determining the locations
  of service instances

. Provides the optimal API for each client

. Reduces the number of requests/roundtrips.  For example, the API
  gateway enables clients to retrieve data from multiple services with
  a single round-trip.  Fewer requests also means less overhead and
  improves the user experience.  An API gateway is essential for
  mobile applications.

. Simplifies the client by moving logic for calling multiple services
  from the client to API gateway

. Translates from a "standard" public web-friendly API protocol to
  whatever protocols are used internally

The SIP gateway pattern has some drawbacks:

. Increased complexity - the API gateway is yet another moving part
  that must be developed, deployed and managed.

. Increased response time due to the additional network hop through
  the API gateway - however, for most applications the cost of an
  extra roundtrip is insignificant.

=== SIP Dataset Service

The SIP Dataset Service provides starting points for creating
analyses.  Administrators load information about datasets (including
so called semantic metadata) into SIP, which is used to create
analyses.  The information about datasets includes the location of the
data, its schema in the form of columns, data types of columns and
so on.  Clients can enumerate datasets and retrieve descriptions of
them for use when creating analyses.

=== SIP Analysis Service

The SIP Analysis Services allows creating, reading, updating and
deleting analyses.  Analyses are used to execute queries on data.  An
analysis is created based on information about a dataset, also known
as semantic metadata.  An analysis can contain one or more artifacts,
each of which contain a set of columns.  Each column in an analysis
has a number of properties, for example if it is selected, or joined
with another column.  These properties affect how the analysis is
translated into a query that is exected.

=== SIP Execution Service

The SIP Execution Service enables executing analyses.  It takes an
analysis to execute as input, translates it into a query and executes
the query and finally provides the results back to the client.

.Figure: Executing an analysis using the SIP Execution Service
plantuml::sip-design/figure-execution-sequence.pum[]

The SIP Execution Service supports two types of storage: Apache Spark
and Elasticsearch.  Analyses of type report are executed on Apache
Spark clusters, while analyses of type pivot and chart are executed on
Elasticsearch clusters.

=== SIP Workbench Service

The SIP Workbench Service enables executing Workbench related operation.  It takes an
project definition to execute as input, translates it into a Datalake operation and records
the operation's activity in MaprDB and finally provides the results back to the client.

.Figure: Executing an analysis using the SIP Workbench Service
plantuml::sip-design/figure-workbench-sequence.pum[]

The SIP Workbench Service supports three types of storage: Apache Spark,
MaprDB & Elasticsearch. This module supports & exposes xdf-nextgen related REST API,
semantic metadata configuration REST APU & data wrangling related REST API.

The Workbench Service provides a REST API on top of which the various
Workbench operations in the Web user interface are implemented.  The
Workbench Service internally uses the Metadata Library to list and
work with dataset information in MapR-DB.  Additionally it uses a
queuing mechanism for executing dataset transformations through the
Workbench Executor component.

.SIP Workbench Components
plantuml::sip-design/figure-components.pum[]

.SIP Workbench Executor
plantuml::sip-design/figure-executor.pum[]

Workbench transformations are implemented using XDF components.
Invoking an XDF component involves input and output to the data lake,
or another location such as Elasticsearch.  The Workbench Service
invokes XDF-NG components using the XDF-NG component interface.
Datasets are internally stored as JSON documents in MapR-DB. The
entries are created by XDF components as part of execution and
accessed using the BDA Metadata library.

=== SIP Storage Proxy Service

SIP Proxy Service will act as proxy for our storage i.e to make
consumables application agnostic to any specific store.  The intention
of this services to provide access behind our gateway for our polyglot
persistence layer (Elasticsearch, Datalake, RDMS & MapR-DB).

One of the reason to access this service to perform transformation at
backend service and API consumer just needs to deal with two common
formats i.e JSON or Tabular (flat structure CSV) irrespective of
storage layer.

.Figure: Executing an data query using the SIP Proxy Service via SIP Gateway Service
plantuml::sip-design/figure-proxy-sequence.pum[]

The request (link:sip-developer/index.html[SIP Developer Guide]) body shall provide the query,
storage type & other details. The below are salient feature for the service which are as follows:

[[proxy-goals]]
[role="incremental"]
* It will return either in JSON or Tabular Format.  ES returns in JSON
   format in terms of search, it should be converted into Tabular
   format if in the request body tabular format is requested.
* Input JSON Schema Validation.
* support create, search, update, delete & aggregate operations.
* It should support to flatten our in house build pivot format.
* Search results will provided in paginated format either in JSON or
  Tabular format.
* Implicit ES Query validation.
* Every incoming request to this story proxy service will be validated
  in gateway service layer.
* It provides CRUD REST API on top of MapRDB store. The user of the
  API can store any form of JSON data adhering to certain structure
  i.e request & response specification.

=== SIP Batch Ingestion Service

SIP Batch Ingestion Service allows to pull batch of data at uniform
interval (can be defined by user) of time.  It will facilitates to
pull data from remote source like *(SFTP, SCP, S3, JDBC etc).*
Currently with it supports only SCP/SFTP.

The REST API of this service is HATEOS Complaint API. To get an
overview of the self descriptive API, it can accessed using URL
(http://hostname/saw/services/batch,
http://hostname/saw/services/batch/profiles)

.Figure: Saw Batch ingestion request & response flow
plantuml::sip-design/figure-batch-sequence.pum[]

Below are the salient feature which are as follows:

[[batch-ingestion-goals]]
[role="incremental"]
* Ability to setup a channel and provide channel information
* Ability to setup a route and provide route information
* Test connectivity of both channel & source.
* Tracking from source to drop.
* Monitoring.
* Scheduling the data retrieval from the source.
* Supports various protocol to pull data.

High level Entity Relationship diagram

.Figure: SIP Batch Ingestion ER Diagram
plantuml::sip-design/figure-batch-er-diagram.pum[format=svg]


The above entities are used to hold the base of Batch Ingestion
module.  Entity BIS_ROUTE is used to hold the details of route i.e it
holds the details of destination, frequency etc etc.  Entity
BIS_CHANNEL is used to hold the details of channel i.e it holds the
details of data channel.  Entity BIS_FILE_LOGS is used to log details
related to the files or data retrieved from the custom. Entity BIS_JOB 
holds job level info. Job status will be updated based on all transfers 
executed in the schedule for the route. 

.Figure: SIP Batch Ingestion Component Diagram
plantuml::sip-design/figure-batch-component-diagram.pum[format=svg]

SIP Batch Ingestion Service implementation is provided as part of
batch plugin implementation based on channel type. 
Ex: sip-batch-plugin-sftp, sip-batch-plugin-s3. Each of plugin
has implementation for file transfer and retry logic for corresponding
channel type.

High Availability & Resiliency

SIP Batch Ingestion Services provides HA providing multiple instances
of services up & running if one goes down & other available services
will serves the request. BIS also monitors it's dependent services
such as scheduler services etc.  BIS API's provides resiliency to
failure providing configurable retry techniques using circuit breaker
pattern which triggers on the occasion of network glitches. If
transferring gets interrupted due to network glitches. It
automatically heals inconsistent state, reinitiate the transfer again
& make sure data has been received. It also takes care of partial data
or corrupted data on destination host to be removed.

=== SIP Semantic Service

The SIP Semantic Service enables the consumer to store the semantic
metadata of SIP. The intention of this services to provide CRUD
operations to deal with semantic metadata

.Figure: Executing an data query using the SIP Proxy Service
plantuml::sip-design/figure-semantic-sequence.pum[]

1. Create Integrated Semantic Node JSON structure for both elastic
search as well as data lake data pods.
2. The structure is consistent with that used by SIP Analyze module
and Observe modules in the store.
3. This service should be consumable by
  . SIP Analyze Module
  . SIP Workbench Module

==== Apache Spark

The Apache Spark executor supports analyses of type report.

Reports are executed as Spark SQL queries running on an Apache Spark
cluster.  The queried data is stored as Parquet files in the data
lake.  The report execution functionality is provided by two
components: the Transport Service and the Transport Service Executor.

The Transport Service provides an internal REST API for SIP Web to
use, including operations to execute a report.  When a report is
executed, the Transport Service writes a message requesting execution
to a message queue.  The message queue is implemented using MapR
streams.  The Transport Service Executor consumes messages from the
queue and executes queries accordingly.

Executors are run in two different modes: fast and regular.  The fast
executors read from the fast queue to which preview and onetime
executions are sent, with expectations of lower latency using
techniques such as preallocated Spark contexts.  The regular executors
read from the regular queue to which scheduled executions are sent.
Using two different queues limits the resources provided to
potentially heavy and long-running scheduled executions to avoid
blocking the more time-sensitive preview and onetime executions.

The queue approach with executors in separate processes is used due to
the limitation of having one Spark context per Java virtual machine.
The number of executors of each type is configured statically in the
SIP environment configuration and used during deployment.  The report
execution concurrency limit follows from the number of executors
configured for each type.

As a preventive measure, executors restart the Java virtual machine
after handling an execution.  This avoids building up state between
executions that can be a source of errors.

When an analysis of type report is executed by the Transport Service,
the results are stored as newline-delimited JSON in the data lake.
When results need to be read back by the Transport Service, it reads
the newline-delimited JSON file in the data lake over the MapR-FS.
The results can then be streamed to avoid reading the entire results
into memory at the same time which might lead to out of memory errors.

==== Elasticsearch

The Elasticsearch executor supports analyses of types pivot and chart.

=== SIP Export Service

The SIP Export Service enables exporting analysis executions to file
formats such as Microsoft Excel.  It calls the SIP Execution Service
to retrieve the execution result, generates the desired output file
format and finally provides it to the client over email and/or on
FTP/SFTP configured locations.

=== SIP Scheduler Service

The SIP Scheduler Service triggers execution of analyses based on
their configured schedule.  The SchedulerService is a Spring Boot
based micro-service, which provides Api to create, manage and trigger
schedules.  It also triggers dispatch request to saw-export service,
if analysis execution result needs to be dispatched.

Internally it uses the Quartz scheduler framework for create, manage
and trigger analysis schedules with mariaDB as job store. The
Scheduler Service does not monitor the actual execution or its
results, but only triggers the start of execution.

=== SIP Observe Service

The SIP Observe Service enables creating, reading, updating and
deleting dashboards.

== SIP Security

The SIP Security module provides authentication and privilege services
to other modules.  It is implemented as a microservice in Java and the
Spring Framework and uses a MariaDB database to persist authentication
and privilege information.

.Figure: The SIP Security Service and dependencies
plantuml::sip-design/figure-security.pum[]

A client authenticated to the SIP Security Service by sending a to the
REST API.  The credentials and privileges are checked against the SIP
Security database, after which a token is issued and returned in the
response to the client.

.Figure: Authenticating a client using the SIP Security Service
plantuml::sip-design/figure-security-sequence.pum[]

== SIP DSL

SIP DSL JSON based high level library build for writing and running
SIP queries against SIP platform with Elasticsearch, DataLake etc. SIP
DSL supports aggregation which can be used for Pivot, Chart and report
structure to visualize the data into platform.

.Figure: SIP-DSL sequence Diagram with platform integration
plantuml::sip-design/figure-SIP-DSL-sequence.pum[]

= Security

By default SIP sends data over the network and store data in
persistent storage in an unencrypted form.  SIP also optionally
supports encryption of data in flight and at rest.

== Data in flight

Data in flight between SIP services are secured using HTTPS.  Data in
flight between SIP services and MariaDB, MapR and Elasticsearch are
also secured using SSL.  Data in flight internally inside MariaDB
Galera clusters, MapR clusters and Elasticsearch clusters are secured
using the respective vendor's default intracluster encryption
solution.

== Data at rest

Data at rest is encrypted using each data storage's respective default
encryption solution.  See the documentation of MariaDB, MapR and
Elasticsearch respectively.

Connections between SIP services use certificates signed by an
internal certificate authority (CA).  The CA is located on the SIP
node with the `sip-admin` role.

NOTE: The `sip_secure` configuration parameter must be set before the
first installation of SIP and not changed thereafter.  Changing the
value after the initial installation for an existing environment is
not supported.

= Monitoring

== Prometheus

Prometheus is used for metrics collection and storage.  It allows
developers to troubleshoot the system and operations to monitor health
and resource usage.  Prometheus consoles are used to create views of
metrics that are typically of high interest.

== Grafana

Grafana is additionally provided for visualization of metrics in the
Prometheus database, due to the wide availability of dashboards for
standard components.

.Monitoring using Prometheus and Grafana
[plantuml]
----
database Prometheus
Prometheus --> [Service #1]
Prometheus --> [Service #2]
Prometheus --> [Service #N]
[Grafana] -> Prometheus
----

= High availability

SIP is required to provide high availability of its services.  If one
node in the SIP environment fails or becomes unavailable, services are
expected to keep working normally.

== Health checks

High availability is achieved using different techniques based on the
type of the service.  Common to all services are the use of health
checks.  Services provide health checks to indicate if they:

* Are able reachable over the network
* Have been successfully configured
* Are able to respond to service requests
* Have all service dependencies healthy

Clients of a service use health checks to find out of an upstream
service is healthy.

.Clients check health of upstream service
[plantuml]
----
[Client] .> health
health - [Service]
----

Health checks are implemented using HTTP requests and responses at
known paths exposed by each service.

.Health check HTTP request and response example
[source, http]
----
GET /actuator/health HTTP/1.1

HTTP/1.1 200
Content-Type: application/json

{
  "status": "UP",
  "details": ...
}
----

Health checks enable service clients (which can be external or other
SIP services) to only route requests to service instances which are
indicated as being healthy.  See the SIP Operations Guide for more
details on service health checks.

.Routing HTTP requests by service health
[plantuml]
----
component [HAProxy] as HaProxy

component [Gateway #1] as Gateway1
component [Gateway #2] as Gateway2
component [Gateway #N] as GatewayN

component [Service #1] as Service1
component [Service #2] as Service2
component [Service #N] as ServiceN

HaProxy ..> Gateway1 : proxy
HaProxy ..> Gateway2 : proxy
HaProxy ..> GatewayN : proxy

Gateway1 ..> Service1 : proxy
Gateway2 ..> Service2 : proxy
GatewayN ..> ServiceN : proxy
----

== High availability proxy

SIP provides a high availability proxy by default, which allows
external clients to connect to a single host, which in turn routes the
request to the appropriate service instance based on health checks.
This is implemented using http://www.haproxy.org/[HAProxy].

Using the high availability proxy simplifies SIP client requirements,
because it removes the need for clients to keep track of multiple SIP
service instances and their health statuses.  The downside of using it
is that if the high availability proxy itself becomes unavailable, for
example due to the node that it is running on failing, clients will
not be able to connect at all.  To make also the HAProxy service
highly available, configure redundant HAProxy nodes that listen to a
virtual IP maintained by Keepalived.

.High availability proxy for services
plantuml::sip-design/figure-ha-proxy.pum[]

== High availability for stateless services

SIP provides high availability for stateless services by running
multiple redundant instances of them on separate nodes.  If one node
fails and makes the service running on that node unavailable, the
service instance on the other node can keep serving requests.

:quartz_doc: http://www.quartz-scheduler.org/documentation/
:quartz_cluster: quartz-2.x/configuration/ConfigJDBCJobStoreClustering.html

The Scheduler Service additionally runs the Quartz scheduler in
{quartz_doc}/{quartz_cluster}[clustered mode], which ensures that
scheduled tasks continue to be executed even if one of the Scheduler
Service instances becomes unavailable.  The clustered mode setting
ensures that each scheduled task is executed by only one of the
instances.  The Quartz scheduler is configured to use MariaDB as its
job store, which itself is highly available through the use of a
MariaDB Galera cluster setup.

.High availability for Scheduler Service
plantuml::sip-design/figure-ha-scheduler.pum[]

== High availability for stateful services

Services that store some kind of state, such as a database, require
each their own solutions to provide high availability.  The only
stateful service is the SIP Security Service, which manages a MariaDB
database.

The SIP Security Service provides high availability by running the
database in a multi-master mode using a MariaDB Galera cluster setup.
In case a single cluster member becomes unavailable, the rest of the
cluster members will continue providing service.  All cluster members
are equal and can be used for both read and write operations.  Clients
can therefore connect to any cluster member, and do not need to
contain logic for following or failing over to a specific member.  All
writes are replicated synchronously across the entire cluster to
ensure consistency and availability.

.High availability for MariaDB
plantuml::sip-design/figure-ha-mariadb.pum[]

= Modules

== Modules overview

SIP provides end users three modules: Analyze, Observe and Workbench.
Additionally SIP is organized into three implementation layers: Web,
Services and Security.  The figure below explains the relation between
modules and service layers.

.SIP Modules and layers
ditaa::sip-design/figure-modules.txt[separation=false]

The web applications are implemented using AngularJS, while services
are implemented using Spring Boot.  The Metadata Library is a shared
Java library.

NOTE: The Analysis and Execution Services shown above are currently
bundled together as the Transport Service, implemented in Scala and
Play.

== Product modules

The SIP platform additionally supports so called _product modules_.
They are independently developed and released modules providing
product-specific analytics functionality, that are deployed on top
of SIP.  They build on the capabilities provided by the SIP REST API.
