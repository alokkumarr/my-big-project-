= SIP Developer Guide
include::header.adoc[]
// Show only one level of sections due to the large amount of sections
// coming from the automatically generated REST API documentation
:toclevels: 1

This guide explains the Synchronoss Insights Platform (SIP)
application programming interface (API).  It describes available
operations, request and response structures and other information
required to integrate with SIP.

The SIP API consists of a number of separate services, each of which
is documented in its own section below.  The REST API is accessed over
HTTP and request and response bodies are mostly in JSON format.
Requests to SIP require authentication, as described in the
<<Authentication>> section.

= Authentication

This section describes different ways clients can authenticate
themselves to SIP.

== Authenticate using credentials

To authenticate a client, the client needs to provide credentials.  In
response it will receive a token which can be used with subsequent
requests to the SIP API.

The HTTP request:

include::{snippets}/authenticate/http-request.adoc[]

The HTTP response:

include::{snippets}/authenticate/http-response.adoc[]

== Authenticate using single sign-on JSON Web Tokens

SIP supports single sign-on authentication integration using JSON Web
Tokens (JWT).  A third party system can provide a token to a client
that authenticates it to SIP.  This relieves the client from having to
authenticate itself to SIP using credentials.

=== Creating a JSON Web Token for single sign-on

The third party system that already has authenticated the client
constructs a JSON Web Token as shown in the sample Java code below.

.Sample Java code for creating a JSON Web Token for single sign-on
[source,java]
----
public String createToken() {
    Long tokenValid = 5 l;
    String secretKey = "Dgus5PoaEHm2tKEjy0cUGnzQlx86qiutmBZjPbI4y0U="
    Map < String, Object > map = new HashMap();
    map.put("valid", true);
    map.put("validUpto", System.currentTimeMillis() + tokenValid * 60 * 1000);
    map.put("validityReason", "");
    map.put("masterLoginId", "sawadmin@synchronoss.com");
    logger.info("Request received to process single sign-on");
    String jwt = Jwts.builder()
        .setSubject("sawadmin@synchronoss.com")
        .claim("ticket", map)
        .setIssuedAt(new Date())
        .signWith(SignatureAlgorithm.HS256, secretKey)
        .compact();
    return jwt;
}
----

=== Guidelines for single sign-on requests

- The secret key to use for signing the JSON Web Token is generated
  and set by the SIP administrator in the environment configuration,
  as described in the SIP Operations Guide
- The algorithm to be used for signing the JSON Web Token is HS256
  symmetric
- Clients should set "Cache-Control: no-store" header in their
  requests
- Clients should set the token expiration ("validUpto" claim in the
  JWT) to a low value, to ensure tickets have a limited lifetime

=== Sample single-sign on URL and request flow

The third party system that has already authenticated the user should
send an HTTP redirect to SIP as shown below, which includes the JSON
Web Token that will authenticate the user to SIP.

[source,http]
----
http://localhost/web/#!/authenticate?jwt=eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJzYXdhZG1pbkBzeW5jaHJvbm9zcy5jb20iLCJ0aWNrZXQiOnsidmFsaWRVcHRvIjoxNTE5MTI3NjkwNzUzLCJ2YWxpZCI6dHJ1ZSwidmFsaWRpdHlSZWFzb24iOm51bGwsIm1hc3RlckxvZ2luSWQiOiJzYXdhZG1pbkBzeW5jaHJvbm9zcy5jb20ifSwiaWF0IjoxNTE5MDQxMjkwfQ.KPQ-tairJG7c7iWPZ-qxwTVwjPd4yo4kBRsNHwenLCw
----

The HTTP request:

include::{snippets}/sso-authentication/http-request.adoc[]

The HTTP response:

include::{snippets}/sso-authentication/http-response.adoc[]

= Example requests and responses

This section shows example request and responses from the SIP API.

== Semantic Service

Clients can use the Semantic service to discover available metrics.

=== List metrics

A client can list the metrics available in the Semantic Service.
Metrics can be used to create analyses.

The HTTP request:

include::{snippets}/list-metrics/http-request.adoc[]

The HTTP response:

include::{snippets}/list-metrics/http-response.adoc[]

== Scheduler Service

Clients can schedule analyses for export using the Scheduler Service.

=== Create schedule

Create a schedule to start exporting an analysis on specific times.

The HTTP request:

include::{snippets}/create-schedule/http-request.adoc[]

The HTTP response:

include::{snippets}/create-schedule/http-response.adoc[]

=== Update schedule

Update a schedule to change the times at which an analysis is
exported.

The HTTP request:

include::{snippets}/update-schedule/http-request.adoc[]

The HTTP response:

include::{snippets}/update-schedule/http-response.adoc[]

=== List schedule

List existing schedules of analyses that are to be exported at given
times.

The HTTP request:

include::{snippets}/list-schedule/http-request.adoc[]

The HTTP response:

include::{snippets}/list-schedule/http-response.adoc[]

== Enable case insensitive filter

SIP supports the case insensitive filter options for data lake and
Elasticsearch data sources.

=== Elasticsearch

To support case insensitive filter in elasticsearch type analysis
below settings needs to be included, while creating the elasticsearch
index mapping to allow the search as case insensitive:

    "settings": {
        "analysis": {
          "analyzer": {
            "analyzer_custom": {
              "type": "custom",
              "filter": [
                "lowercase"
              ],
              "tokenizer": "keyword"
            }
          }
        }
      }

Update the Elasticsearch fields mapping with custom analyzer as below
for those fields, which are all eligible for case insensitive (string
type fields):

    "product" : {
           "type" : "keyword",
           "fields" : {
             "keyword" : {
               "type" : "keyword",
               "ignore_above" : 256
             },
             "filter" : {
               "type": "text",
               "analyzer": "analyzer_custom"
             }
           }
         }
       }

NOTE: The above settings are optional to support case insensitive
filtering.  If these settings are not applied, elasticsearch analysis
filters will be case sensitive.

=== Data Lake

To support case insensitive filter for data lake analysis, there are
no additional setting required. By default SIP has native support for
this option.

= Security Service API

The Security Service provides authentication, role and category
information.

include::{snippets}/apidoc-security/paths.adoc[]
include::{snippets}/apidoc-security/definitions.adoc[]
include::{snippets}/apidoc-security/security.adoc[]

= Semantic Service API

The Semantic Service provides a catalogue of datasets that clients can
use to create analyses.

include::{snippets}/apidoc-semantic/paths.adoc[]
include::{snippets}/apidoc-semantic/definitions.adoc[]
include::{snippets}/apidoc-semantic/security.adoc[]

= Scheduler Service API

The Scheduler Service allows scheduling analyses to be executed at
given times.

include::{snippets}/apidoc-scheduler/paths.adoc[]
include::{snippets}/apidoc-scheduler/definitions.adoc[]
include::{snippets}/apidoc-scheduler/security.adoc[]

= Observe Service API

The Observe Service allows clients to follow key metrics.

include::{snippets}/apidoc-observe/paths.adoc[]
include::{snippets}/apidoc-observe/definitions.adoc[]
include::{snippets}/apidoc-observe/security.adoc[]

= Proxy Service API

The Proxy Service provides clients a unified interface to storage.

include::{snippets}/apidoc-proxy/paths.adoc[]
include::{snippets}/apidoc-proxy/definitions.adoc[]
include::{snippets}/apidoc-proxy/security.adoc[]

= Workbench Service API

The Workbench Service allows clients to create transformations on
datasets.

include::{snippets}/apidoc-workbench/paths.adoc[]
include::{snippets}/apidoc-workbench/definitions.adoc[]
include::{snippets}/apidoc-workbench/security.adoc[]

= Realtime Ingestion Service API

The Realtime Ingestion Service allows clients to submit events for
ingestion.

include::{snippets}/apidoc-rtis/paths.adoc[]
include::{snippets}/apidoc-rtis/definitions.adoc[]
include::{snippets}/apidoc-rtis/security.adoc[]

= Export Service API

The Export Service allows clients to export reports and send
email in various formats including csv, xls, zip..etc

include::{snippets}/apidoc-export/paths.adoc[]
include::{snippets}/apidoc-export/definitions.adoc[]
include::{snippets}/apidoc-export/security.adoc[]

= XDA Sample Application on Docker

This section will describe list of steps to use the XDA Sample application on the Docker environment.

== Prerequisites Script

This script will register the XDA application on maprdb and create all required folder structures on MapR FS. Also as a workaround to fix the Elasticsearch port issue(8200), this script will also update the ES port to 9200 on sip-elastic docker container and restart the service.

.Command
----
/home/mapr/sip-xda-prereq.sh
----

=== Running XDA Sampleapp

Developer can run each individual XDA Component or complete end-to-end pipeline using this script. Sample configurations and sample input file location will pop up as suggestions once the below shell script is run.

.Command
----
/home/mapr/sip-xda-run.sh
----

User can then select to run requied individual XDA Component or run end-to-end Pipeline component by providing the input file or input file location. Developer will provide the input and output locations for each component in the configuration files. 

For this XDA Sample application, Parsar component will run first on the input files and the output of the parser can be used as input for Transformer or SQL component by making necessary configurations.

Note: Developers should remember that input files in RAW folder are archived once the parser component is run and might observe the null pointer error if there is no input file provided while running parser component the second time.

Since the script requests for the configuration file and sample file locations, developers can either use the same files as shown up in the suggestions with the new configurations or create a their own file with new configurations using new input data files while developing the new applications.

==== Input and Output Location 

Defalut Raw folder for input files and output files after processing ( this can be changed according the developer preference if required in configuration file )

.XDA Raw files location:
----
/data/bda/xdf-sample-data/raw

Command to check the input files: hadoop fs -ls /data/bda/xdf-sample-data/raw
----

.XDA Output files location for all components:
----
/var/sip/sip-xda-sampleapp/dl/fs/dout/

Command to check the output files: hadoop fs -ls /var/sip/sip-xda-sampleapp/dl/fs/dout/
----

.ESLoader output indices can be viewed by using the below CLI command from sip-mapr container using CURL
----
curl http://sip-elastic:9200/_cat/indices?pretty
---- 
