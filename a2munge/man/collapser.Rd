% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/collapser.R
\name{collapser}
\alias{collapser}
\alias{collapser.data.frame}
\alias{collapser.tbl_spark}
\title{Date Interval Ceiling Value function}
\usage{
collapser(df, measure_vars, unit, side, time_zone, output_suffix)

\method{collapser}{data.frame}(df, measure_vars, unit, side,
  time_zone = "UTC", output_suffix = "CEI")

\method{collapser}{tbl_spark}(df, measure_vars, unit, side, time_zone = "UTC",
  output_suffix = "CEI")
}
\arguments{
\item{df}{Dataframe}

\item{measure_vars}{Input Date column for which ceiling date has to be derived}

\item{unit}{Period for which collapsing logic has to be applied}

\item{side}{Direction in which collapsing logic has to be applied}

\item{time_zone}{Timezone to be considered for Date manipulation. Default is UTC.}

\item{output_suffix}{Suffix to be added to the new column generated by the function}
}
\value{
returns DataFrame with ceiling date value derived on column {INPUT_COLUMN_NAME}_CEI
}
\description{
This is a function to extract the maximum possible value for a date column
for a given interval
}
\details{
For R data frames, the base ceiling date function will be used from the lubridate
package with logic to negate the resulting date value by 1 period of the relevant
interval Function returns a date value which will be the maximum possible value.
For Spark data frames, SQL logic has been coded to get the ceiling date. The output
format will be yyyy-MM-dd or yyyy-MM-dd HH:mm:ss only since Spark SQL does not allow
formatted Dates
}
\examples{

library(dplyr)
library(lubridate)

date_func_df <- data.frame(TIME_COL = as.POSIXlt(c("2017-01-01 10:15:15", "2017-09-23 14:26:59", "2017-11-15 05:05:05", "2018-05-11 08:15:18", "2018-03-27 23:59:59")), stringsAsFactors = FALSE)

collapser(date_func_df, "TIME_COL", "month", "end")
}
