connector = http
semantic = {
  host = ${connector}"://localhost:9500"
  endpoint = "/internal/semantic/workbench/"
}

report.executor = {
  path= "/var/sip"
}

sip.ssl = {
  enable = false
}

spark = {
  master = "local[*]"
  executor.memory.regular = "512M"
  executor.memory.fast = "512M"
  executor.instances.fast="1"
  executor.instances.regular="2"
  cores.max.regular = "2"
  cores.max.fast = "2"
  driver.memory = "2G"
  spark.driver.port.fast = "9801"
  spark.driver.port.regular = "9802"
  spark.blockManager.port.fast = "9803"
  spark.blockManager.port.regular = "9803"

  # This will contains all the configuration
  yarn = {

  }

  sql-executor = {

    wait-time = "120"
    inline-data-store-limit-bytes = 268435456
    preview-rows-limit = 10000
    executor-restart-threshold=1

    # The location is to store results genereted by SQL Executor
    output-location = "/var/sip/services/data/saw/sql-executor/output"
    semantic-layer-tmp-location = "/main/data/saw/sql-executor/temp"

    # Use line-delimited JSON as the output format by default, for
    # simplicity of streaming results out of the data lake
    output-type = "json"

    jar-location = "/opt/bda/sip-executor/lib"
  }
}
